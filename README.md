# Logistic Regression From Scratch

Coding up Logistic regression from scratch using NumPy and SciPy. This implementation includes batch gradient descent
with an adjustable learning rate and BFGS solver.

Comparison with scikit-learn shows that it converges to the same results. The number of iteration is lower due to a better default for the learning rate.
